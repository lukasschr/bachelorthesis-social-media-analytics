{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca65f0f",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a81e9",
   "metadata": {},
   "source": [
    "- [Data Collection](#data_collection)\n",
    "- [Data Exploration](#data_exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f1c00",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d20ada",
   "metadata": {},
   "source": [
    "## Data Collection <a name=\"data_collection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35d5c3",
   "metadata": {},
   "source": [
    "Um später aussagekräftige Modelle erstellen zu können, müssen im ersten Schritt die dafür notwendigen Daten gesammelt und ein Datensatz erstellt werden. Dazu werden Beiträge auf der Plattform Twitter gesammelt und in einer Liste gespeichert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df67aa7",
   "metadata": {},
   "source": [
    "#### 1. Daten sammeln\n",
    "\n",
    "Um ausschließlich relevante und die Branche betreffende Twitter-Beiträge zu sammeln werden folgende Suchparameter übergeben:\n",
    "- hashtags: #technology, #tech, #innovation\n",
    "- language: en\n",
    "- period: until:2023-03-31 since:2022-10-01\n",
    "- limit: 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6cbf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "from src.data.nitter_scraper_standalone_v2 import *\n",
    "from datetime import datetime\n",
    "\n",
    "# set search parameters\n",
    "query = '%28%23technology+OR+%23tech+OR+%23innovation%29+lang%3Aen&e-nativeretweets=on'\n",
    "since = datetime(2022, 10, 1)\n",
    "until = datetime(2023, 3, 31)\n",
    "limit = 1_000_000\n",
    "\n",
    "\n",
    "# collect twitter posts\n",
    "scrape(q=query, since=since, until=until, limit=limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc6ceb",
   "metadata": {},
   "source": [
    "#### 2. Datensatz anzeigen\n",
    "\n",
    "Nachdem die Twitter-Beiträge gesammelt wurden, werden diese in ein Dataframe transformiert und angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b005f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.nitter_scraper_standalone_v2 import Tweet, TweetScraper\n",
    "import pandas as pd\n",
    "\n",
    "# load tweet objects\n",
    "list_of_tweets = TweetScraper.load_collected_tweets(path='../data/raw/twitter_tweets_raw.pkl')\n",
    "\n",
    "# transform into a dataframe\n",
    "dict_of_tweets =  [{\"url\": tweet.url, \"date\": tweet.date, \"rawContent\": tweet.rawContent} for tweet in list_of_tweets]\n",
    "df = pd.DataFrame(dict_of_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fded111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/_Bob_S/status/164159110508...</td>\n",
       "      <td>Mar 30, 2023 · 11:59 PM UTC</td>\n",
       "      <td>Govt IT security isnt 'a nice thing to do': it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/WYSIWYGVentures/status/164...</td>\n",
       "      <td>Mar 30, 2023 · 11:59 PM UTC</td>\n",
       "      <td>ISC West 2023: Cyberattackers Are Targeting Ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/HackerAran7/status/1641591...</td>\n",
       "      <td>Mar 30, 2023 · 11:59 PM UTC</td>\n",
       "      <td>What’s the hack. #stem #science #stemeducation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/bytefeedai/status/16415909...</td>\n",
       "      <td>Mar 30, 2023 · 11:59 PM UTC</td>\n",
       "      <td>BuzzFeed Is Using AI To Write SEO-Bait Travel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   \n",
       "0  https://twitter.com/_Bob_S/status/164159110508...  \\\n",
       "1  https://twitter.com/WYSIWYGVentures/status/164...   \n",
       "2  https://twitter.com/HackerAran7/status/1641591...   \n",
       "3  https://twitter.com/bytefeedai/status/16415909...   \n",
       "\n",
       "                          date   \n",
       "0  Mar 30, 2023 · 11:59 PM UTC  \\\n",
       "1  Mar 30, 2023 · 11:59 PM UTC   \n",
       "2  Mar 30, 2023 · 11:59 PM UTC   \n",
       "3  Mar 30, 2023 · 11:59 PM UTC   \n",
       "\n",
       "                                          rawContent  \n",
       "0  Govt IT security isnt 'a nice thing to do': it...  \n",
       "1  ISC West 2023: Cyberattackers Are Targeting Ph...  \n",
       "2  What’s the hack. #stem #science #stemeducation...  \n",
       "3  BuzzFeed Is Using AI To Write SEO-Bait Travel ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# set up jupyter to be able to display the entire dataframe (specifically all columns)\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7be6ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00a74f",
   "metadata": {},
   "source": [
    "## Data Exploration <a name=\"data_exploration\"></a>\n",
    "\n",
    "Nun gilt es den gesammelten Datensatz zu beschreiben, zu untersuchen und abschließend zu bewerten. Die Untersuchung dient dem Zweck die Daten hinsichtlich ihrer Qualität zu bewerten und Maßnahmen für das Data Cleaning zu beschließen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690370a",
   "metadata": {},
   "source": [
    "#### 1. Überblick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a21e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url           object\n",
       "date          object\n",
       "rawContent    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e3019",
   "metadata": {},
   "source": [
    "#### 2. Überprüfe Anforderungen an den Datensatz\n",
    "\n",
    "Um die Qualität der Daten bewerten zu können, muss zuerst sichergestellt werden, ob die Daten auch den zuvor aufgestellen Anforderungen entsprechen. Nachfolgend werden daher folgende Überprüfungen vorgenommen:\n",
    "- Prüfe ob alle Beiträge im angegebenen Zeitraum erstellt wurden\n",
    "- Prüfe ob alle Beiträge Textdaten enthalten\n",
    "- Prüfe ob Duplikate existieren \n",
    "- Prüfe ob alle Beiträge in englischer Sprache sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53f17a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether all posts were created within the selected period\n",
    "# expected result: True\n",
    "import datetime\n",
    "\n",
    "_ = df.copy()\n",
    "_['date'] = _['date'].apply(lambda x: datetime.datetime.strptime(x, \"%b %d, %Y · %I:%M %p %Z\"))\n",
    "\n",
    "_.query('date < \"2022-10-01\" or date > \"2023-03-31\"').empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b059c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if entries have no text\n",
    "# expected result: False\n",
    "\n",
    "df['rawContent'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfec7c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "# expected result: False\n",
    "\n",
    "df['rawContent'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5756da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all texts are in English\n",
    "# expected result: True\n",
    "from langdetect import detect\n",
    "\n",
    "_ = df.copy()\n",
    "\n",
    "# define function to identify language of tweet\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = None\n",
    "    return lang\n",
    "\n",
    "_['lang'] = _['rawContent'].apply(detect_language)\n",
    "_['lang'].eq('en').all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20b3b4",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
