{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85080f53",
   "metadata": {},
   "source": [
    "# Notebook Experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca41280",
   "metadata": {},
   "source": [
    "Dieses Notebook kann dazu verwendet werden, Code außerhalb des durch die anderen Notebooks vorgegebenen Prozesses Code zu schreiben, kleinere Hilfsfunktionen zu definieren und Code zu testen. Typische Anwendungsbeispiele sind unten aufgelistet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed453f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c7f57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870e613",
   "metadata": {},
   "source": [
    "#### Anzeigen des Intermediate Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_feather('../data/intermediate/twitter_tweets_intermediate.feather')\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9d3d6",
   "metadata": {},
   "source": [
    "#### Generierung der list_parameter_combinations.pkl\n",
    "\n",
    "Die Erstellung dieser Datei ist notwenig, um das Hyperparameter Tuning für das Topic Modeling *headless* durchführen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import safe_as_pkl\n",
    "\n",
    "search_space = {\n",
    "    'num_topics': hp.choice('num_topics', [i for i in range(12, 28)]),\n",
    "    'alpha': hp.choice('alpha', ['symmetric', 'asymmetric', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "    'eta': hp.choice('eta', ['symmetric', 'auto', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "    'chunksize':  hp.choice('chunksize', [5000]),\n",
    "    'iterations': hp.choice('iterations', [50, 100]),\n",
    "    'passes': hp.choice('passes', [8, 9, 10])\n",
    "}\n",
    "safe_as_pkl(search_space, '../data/modeling/tm_ht_search_space.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e3ca9",
   "metadata": {},
   "source": [
    "#### Erstellen interaktives Topic Modeling\n",
    "\n",
    "Der nachfolgende Code wird verwendet, um die interaktive HTML-Seite für das Topic-Modeling zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "from src.utils import load_pkl\n",
    "\n",
    "# load optimized lda model\n",
    "lda_model = load_pkl('../models/optimized_lda_model_146.pkl')\n",
    "\n",
    "# generate the interactive HTML page\n",
    "pyLDAvis.enable_notebook()\n",
    "vis_data = pyLDAvis.gensim_models.prepare(lda_model.model, lda_model.corpus, lda_model.dictionary, sort_topics=False)\n",
    "pyLDAvis.save_html(vis_data, '../export/optimized_lda_visualization_146.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd65d7",
   "metadata": {},
   "source": [
    "#### [Grafik] Häufigkeit der Schlüsselwörter innerhalb der Topics\n",
    "\n",
    "Hier werden die barh Charts für die alternative visuelle Darstellung der Topics für die Bachelorarbeit erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.utils import load_pkl\n",
    "\n",
    "def create_chart(topic_id:int, num_keywords:int):\n",
    "    topic_keywords = lda_model.model.show_topic(topic_id-1, topn=num_keywords)\n",
    "    sorted_topic_keywords = sorted(topic_keywords, key=lambda x: x[1])\n",
    "    \n",
    "    keywords = [keyword for keyword, weight in sorted_topic_keywords]\n",
    "    weights = [weight for keyword, weight in sorted_topic_keywords]\n",
    "    \n",
    "    total_weight = sum(weights) # sum the weights of all keywords/terms in the topic\n",
    "    relative_frequencies = [weight / total_weight for weight in weights] # calculate the relative frequency of each keyword/term\n",
    "    y = np.arange(len(keywords)) # create an array for the bar positions\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Consolas'\n",
    "    plt.figure(figsize=(7, 5)) # width, height\n",
    "    plt.barh(y, relative_frequencies, color='#203864')\n",
    "    plt.yticks(y, keywords)\n",
    "    #plt.ylabel('Schlüsselwörter')\n",
    "    plt.xlabel('Relative Häufigkeit')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../export/tm_bchart_topic_{topic_id}.svg', format='svg')\n",
    "    \n",
    "# load optimized lda model\n",
    "lda_model = load_pkl('../models/optimized_lda_model_174.pkl')\n",
    "\n",
    "for i in range(lda_model.model.num_topics):\n",
    "    create_chart(i+1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d2010",
   "metadata": {},
   "source": [
    "#### [Grafik] Topic-Trends & Google Trends Verläufe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils import load_pkl\n",
    "\n",
    "google_trends_data = {\n",
    "    'Blockchain-Technologie': pd.read_csv('../data/modeling/google_trends_data_blockchain.csv', skiprows=2),\n",
    "    'Künstliche Intelligenz': pd.read_csv('../data/modeling/google_trends_data_ai.csv', skiprows=2),\n",
    "    'VR, AR und Metaverse': pd.read_csv('../data/modeling/google_trends_data_vr_ar_metaverse.csv', skiprows=2)\n",
    "}\n",
    "\n",
    "xgb_models = [\n",
    "    load_pkl('../models/xgb_model_4.pkl'),\n",
    "    load_pkl('../models/xgb_model_10.pkl'),\n",
    "    load_pkl('../models/xgb_model_12.pkl')\n",
    "]\n",
    "\n",
    "\n",
    "for model in xgb_models:\n",
    "    gtd = google_trends_data[model.label]\n",
    "    gtd['Woche'] = pd.to_datetime(gtd['Woche'])\n",
    "    gtd.set_index('Woche', inplace=True)\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Consolas'\n",
    "    plt.figure(figsize=(8, 5)) # width, height\n",
    "    \n",
    "    plt.plot(model.timeseries, label='Anzahl Tweets pro Tag', color='#203864')\n",
    "    plt.plot(gtd, label='Google Trend', color='#ffd966')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f'../export/trend_lchart_{model.id}.svg', format='svg') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab66109c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
